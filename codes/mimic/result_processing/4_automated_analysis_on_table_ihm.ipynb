{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKT4p2Ddo62x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp_test_isotonic_4.csv']\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# *************** change only model name + file_name(if DP) in the following line ******************** \n",
    "#model_path = r\"csv_files/decomp_dp_age30_1/test/\"\n",
    "model_path = r\"csv_files/decomp_dp_white_1/test/\"\n",
    "\n",
    "# take the csv files in that directory\n",
    "files = [f for f in listdir(model_path) if fnmatch.fnmatch(f, '*temp_test_isotonic_4*.csv')]\n",
    "#files = [f for f in listdir(model_path) if fnmatch.fnmatch(f, '*age3040_thr_temp_test_isotonic_1*.csv')]\n",
    "#put dp selected model here\n",
    "#files = [f for f in listdir(model_path) if fnmatch.fnmatch(f, 'test_isotonic_subgroup*.csv')]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_demographics(demographics):\n",
    "    y_pred = demographics[\"y_pred\"].values\n",
    "    y_true = demographics[\"y_true\"].values\n",
    "    prediction = demographics[\"calibrated_prediction\"].values\n",
    "    a = result_print(y_true,y_pred, prediction)\n",
    "    return demographics.shape[0], a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import math\n",
    "\n",
    "\n",
    "def result_print(y_true,y_pred,prediction):\n",
    "    #print(\"Confusion Metrix\" , confusion_matrix(y_true, y_pred))\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    #print(\"Accuracy Score \", accuracy)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    #print(\"recall_score\", recall)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    #print(\"precision_score\", precision)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    #print(\"f1_score\", f1)\n",
    "    auc_roc = roc_auc_score(y_true, prediction)\n",
    "    #print(\"roc_auc_score\", auc_roc)\n",
    "    #print(\"precision_recall_curve\", precision_recall_curve(y_true, y_pred))\n",
    "\n",
    "    CM = confusion_matrix(y_true, y_pred)\n",
    "    TN = CM[0][0]\n",
    "    FN = CM[1][0]\n",
    "    TP = CM[1][1]\n",
    "    FP = CM[0][1]\n",
    "    FPR = ((FP)/(FP+TN))\n",
    "    FNR = ((FN)/(FN+TP))\n",
    "    TPR = (TP) / (TP + FN)\n",
    "    TNR = (TN) / (TN + FP)\n",
    "    #print(\"Precision_score (Group 0): \", (TN/(TN+FN)))\n",
    "    precision_0 = (TN/(TN+FN))\n",
    "    #print(\"recall_score (Group 0): \", (TN/(TN+FP)))\n",
    "    recall_0 = (TN/(TN+FP))\n",
    "    #print(\"false_positive_rate: \", FPR)\n",
    "    #print(\"false_negative_rate: \", FNR)\n",
    "    balanced_accuracy = (TPR + TNR) / 2 \n",
    "    #print(\"balanced_accuracy\", balanced_accuracy)\n",
    "    #MCC = ((TP*TN) - (FP*FN)) / (math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))) \n",
    "    MCC = matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    (precisions, recalls, thresholds) = metrics.precision_recall_curve(y_true, prediction)\n",
    "\n",
    "    y_true_inverse = []\n",
    "    for i in y_true:\n",
    "        y_true_inverse.append(1-i)\n",
    "    y_true_inverse = np.array(y_true_inverse)\n",
    "\n",
    "    y_pred_inverse = []\n",
    "    for i in y_pred:\n",
    "        y_pred_inverse.append(1-i)\n",
    "    y_pred_inverse = np.array(y_pred_inverse)  \n",
    "    prediction_inverse = []\n",
    "    for i in prediction:\n",
    "        prediction_inverse.append(1-i)\n",
    "    prediction_inverse = np.array(prediction_inverse)\n",
    "\n",
    "    precision_inv = precision_score(y_true_inverse, y_pred_inverse)\n",
    "    #print(\"precision_score_inv: \", precision_inv)  \n",
    "\n",
    "    f1_inverse = f1_score(y_true_inverse, y_pred_inverse)\n",
    "    #print(\"f1_score (class 0): \", f1_inverse)\n",
    "\n",
    "    (precisions_inverse, recalls_inverse, thresholds_inverse) = metrics.precision_recall_curve(y_true_inverse, prediction_inverse)\n",
    "\n",
    "    auc_roc_inverse = roc_auc_score(y_true_inverse, prediction_inverse)\n",
    "    #print(\"roc_auc_score (class 0)\", auc_roc_inverse)\n",
    "\n",
    "  \n",
    "\n",
    "    (precisions_inverse, recalls_inverse, thresholds_inverse) = metrics.precision_recall_curve(y_true_inverse, prediction_inverse)\n",
    "\n",
    "\n",
    "    auprc = metrics.auc(recalls, precisions)\n",
    "    #print('PR Score_class1: ', auprc)\n",
    "\n",
    "    auprc_inverse = metrics.auc(recalls_inverse, precisions_inverse)\n",
    "    #print('PR Score_class0: ', auprc_inverse)\n",
    "\n",
    "\n",
    "    result_return = []\n",
    "    k = 3\n",
    "\n",
    "    result_return.append(round(recall,k))\n",
    "    result_return.append(round(precision,k))\n",
    "    result_return.append(round(auprc,k))\n",
    "    result_return.append(round(f1,k))\n",
    "    result_return.append(round(recall_0,k))\n",
    "    result_return.append(round(precision_0,k))\n",
    "    result_return.append(round(auprc_inverse,k))\n",
    "    result_return.append(round(f1_inverse,k))\n",
    "    result_return.append(round(accuracy,k))\n",
    "    result_return.append(round(balanced_accuracy,k))\n",
    "    result_return.append(round(auc_roc,k))\n",
    "    result_return.append(round(MCC,k))\n",
    "    #result_return.append(round(auc_roc_inverse,k))\n",
    "    result_return.append(round(FPR,4))\n",
    "    result_return.append(round(FNR,k))\n",
    "    \n",
    "    \n",
    "\n",
    "    return result_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_test_isotonic_4.csv\n",
      "result of temp_test_isotonic_4.csv is posted\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    print(f)\n",
    "    df = pd.read_csv(model_path + f)\n",
    "    full_list = []\n",
    "    \n",
    "    # whole\n",
    "    shape, res_metrics = different_demographics(df)\n",
    "    a = ['whole']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # Male\n",
    "    shape, res_metrics = different_demographics(df[df['GENDER'] == 'M'])\n",
    "    a = ['Male']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # Female\n",
    "    shape, res_metrics = different_demographics(df[df['GENDER'] == 'F'])\n",
    "    a = ['female']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # White\n",
    "    shape, res_metrics = different_demographics(df[df['ETHNICITY'].str.contains(\"WHITE\")])\n",
    "    a = ['White']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # Black\n",
    "    shape, res_metrics = different_demographics(df[df['ETHNICITY'].str.contains(\"BLACK\")])\n",
    "    a = ['Black']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # Hispanic\n",
    "    shape, res_metrics = different_demographics(df[df['ETHNICITY'].str.contains(\"HISPANIC\")])\n",
    "    a = ['Hispanic']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # Asian\n",
    "    shape, res_metrics = different_demographics(df[df['ETHNICITY'].str.contains(\"ASIAN\")])\n",
    "    a = ['Asian']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # age < 30\n",
    "    shape, res_metrics = different_demographics(df[df['AGE'] < 30])\n",
    "    a = ['Age < 30']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # 30 >= age > 40\n",
    "    shape, res_metrics = different_demographics(df[(df['AGE'] >= 30) & (df['AGE'] < 40) ])\n",
    "    a = ['Age [30, 40)']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # 40 >= age > 50\n",
    "    shape, res_metrics = different_demographics(df[(df['AGE'] >= 40) & (df['AGE'] < 50) ])\n",
    "    a = ['Age [40, 50)']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # 50 >= age > 60\n",
    "    shape, res_metrics = different_demographics(df[(df['AGE'] >= 50) & (df['AGE'] < 60) ])\n",
    "    a = ['Age [50, 60)']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # 60 >= age > 70\n",
    "    shape, res_metrics = different_demographics(df[(df['AGE'] >= 60) & (df['AGE'] < 70) ])\n",
    "    a = ['Age [60, 70)']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # 70 >= age > 80\n",
    "    shape, res_metrics = different_demographics(df[(df['AGE'] >= 70) & (df['AGE'] < 80) ])\n",
    "    a = ['Age [70, 80)']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    \n",
    "    # 80 >= age > 90\n",
    "    shape, res_metrics = different_demographics(df[(df['AGE'] >= 80) & (df['AGE'] < 90) ])\n",
    "    a = ['Age [80, 90)']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    # age >= 90\n",
    "    shape, res_metrics = different_demographics(df[df['AGE'] >= 90])\n",
    "    a = ['Age >= 90']+ [shape] + res_metrics\n",
    "    full_list.append(a)\n",
    "    \n",
    "    df_full_list = pd.DataFrame(full_list, columns = [\"Group\", \"Test_data\", \"Recall_C1\",\"Precision_C1\",\"AUC_PR_C1\", \"F1_C1\",\"Recall_C0\",\"Precision_C0\",\"AUC_PR_C0\", \"F1_C0\", \"Accuracy\", \"Balanced_Accuracy\", \"AUC_ROC\", \"MCC\", \"FPR\", \"FNR\"])\n",
    "    #print(df_full_list)\n",
    "    \n",
    "    df_full_list.to_csv(model_path + 'result_'+ f, index=False)\n",
    "    print('result of ' + f + ' is posted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding mean and avg of files:  ['result_temp_test_isotonic_0_1.csv', 'result_temp_test_isotonic_0_2.csv', 'result_temp_test_isotonic_0_3.csv']\n"
     ]
    }
   ],
   "source": [
    "# # Mean of Results  --- given that there are three files to find mean and stdev \n",
    "\n",
    "\n",
    "files = [f for f in listdir(model_path) if fnmatch.fnmatch(f, '*result_temp_test_isotonic*.csv')]\n",
    "print(\"finding mean and avg of files: \", files)\n",
    "\n",
    "# read three files\n",
    "file1 = pd.read_csv(model_path + files[0])\n",
    "file2 = pd.read_csv(model_path + files[1])\n",
    "file3 = pd.read_csv(model_path + files[2])\n",
    "\n",
    "# get column names and Group and Test_data\n",
    "column_name = list(file1.columns)[2:]\n",
    "Group = list(file1[\"Group\"])\n",
    "Test_data = list(file1[\"Test_data\"])\n",
    "\n",
    "# Drop Group and Test_data (No need to do the average them) and convert them to numpy array \n",
    "file1 = file1.drop(columns = [\"Group\", \"Test_data\"]).to_numpy()\n",
    "file2 = file2.drop(columns = [\"Group\", \"Test_data\"]).to_numpy()\n",
    "file3 = file3.drop(columns = [\"Group\", \"Test_data\"]).to_numpy()\n",
    "\n",
    "res = np.stack((file1,file2, file3))\n",
    "\n",
    "average = pd.DataFrame(np.mean(res, axis=0), columns = column_name)\n",
    "stdev = pd.DataFrame(np.std(res, axis=0), columns = column_name)\n",
    "\n",
    "\n",
    "# add Group and Test_data information again\n",
    "average.insert(0, 'Group', Group)\n",
    "average.insert(1, 'Test_data', Test_data)\n",
    "\n",
    "average.to_csv(model_path + '1_AVERAGE.csv', index=False)\n",
    "\n",
    "stdev.insert(0, 'Group', Group)\n",
    "stdev.insert(1, 'Test_data', Test_data)\n",
    "\n",
    "stdev.to_csv(model_path + '2_STDEV.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1588132337301,
     "user": {
      "displayName": "Sharmin Afrose",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmRI-PB90eD46vxZRw7S-OxCOZHIZFwo_EPZC7=s64",
      "userId": "11004693519912286885"
     },
     "user_tz": 240
    },
    "id": "lIdYSjdro62Y",
    "outputId": "835e4e01-f79d-4bf0-e94c-0801bfdb507a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding mean and avg of files:  ['result_temp_test_isotonic_1_1.csv', 'result_temp_test_isotonic_1_4.csv']\n"
     ]
    }
   ],
   "source": [
    "# # Mean of Results of 2 files  --- given that there are three files to find mean and stdev \n",
    "\n",
    "\n",
    "# files = [f for f in listdir(model_path) if fnmatch.fnmatch(f, '*result_temp_test_isotonic*.csv')]\n",
    "# print(\"finding mean and avg of files: \", files)\n",
    "\n",
    "# # read three files\n",
    "# file1 = pd.read_csv(model_path + files[0])\n",
    "# file2 = pd.read_csv(model_path + files[1])\n",
    "\n",
    "# # get column names and Group and Test_data\n",
    "# column_name = list(file1.columns)[2:]\n",
    "# Group = list(file1[\"Group\"])\n",
    "# Test_data = list(file1[\"Test_data\"])\n",
    "\n",
    "# # Drop Group and Test_data (No need to do the average them) and convert them to numpy array \n",
    "# file1 = file1.drop(columns = [\"Group\", \"Test_data\"]).to_numpy()\n",
    "# file2 = file2.drop(columns = [\"Group\", \"Test_data\"]).to_numpy()\n",
    "\n",
    "\n",
    "# res = np.stack((file1,file2))\n",
    "\n",
    "# average = pd.DataFrame(np.mean(res, axis=0), columns = column_name)\n",
    "# stdev = pd.DataFrame(np.std(res, axis=0), columns = column_name)\n",
    "\n",
    "\n",
    "# # add Group and Test_data information again\n",
    "# average.insert(0, 'Group', Group)\n",
    "# average.insert(1, 'Test_data', Test_data)\n",
    "\n",
    "# average.to_csv(model_path + '1_AVERAGE.csv', index=False)\n",
    "\n",
    "# stdev.insert(0, 'Group', Group)\n",
    "# stdev.insert(1, 'Test_data', Test_data)\n",
    "\n",
    "# stdev.to_csv(model_path + '2_STDEV.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rmqG85IeHuEN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YbeBQ38oJ8BV",
    "4zFx6N6n-sab"
   ],
   "name": "automated_analysis_on_table_ihm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
