{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overhead-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "\n",
    "# *************** change dp name in the following line ******************** \n",
    "models = ['original']\n",
    "\n",
    "group = 0 # whole=0; age90 = 14; black=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reasonable-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_AVERAGE.csv']\n",
      "['whole', 3236, 0.6096666666666667, 0.395, 0.4813333333333333, 0.4766666666666666, 0.8756666666666666, 0.945, 0.9766666666666666, 0.9086666666666666, 0.8450000000000001, 0.7426666666666666, 0.8553333333333333, 0.4053333333333333, 0.0124333333333333, 0.039]\n"
     ]
    }
   ],
   "source": [
    "full_list = []\n",
    "full_list_std = []\n",
    "for mod in models:\n",
    "    model_path = r\"csv_files/\"+ mod + \"/test/\"\n",
    "    \n",
    "    if mod =='original':\n",
    "        files = [f for f in listdir(model_path) if fnmatch.fnmatch(f, '*average*.csv')]   \n",
    "        df = pd.read_csv(model_path  + files[0])\n",
    "        full_list.append(list(df.loc[group]))\n",
    "\n",
    "    elif mod == 'decomp_original':\n",
    "        files = [f for f in listdir(model_path) if fnmatch.fnmatch(f, '*result_temp_test_isotonic*.csv')]\n",
    "        df = pd.read_csv(model_path  + files[0])\n",
    "        \n",
    "        full_list.append(list(df.loc[group]))\n",
    "        \n",
    "\n",
    "\n",
    "    print(files)\n",
    "    \n",
    "    \n",
    "    print(list(df.loc[group]))\n",
    "    \n",
    "\n",
    "df_full = pd.DataFrame(full_list, columns= [\"Group\", \"Test_data\", \"Recall_C1\", \"Precision_C1\", \"AUC_PR_C1\", \"F1_C1\", \"Recall_C0\", \"Precision_C0\", \"AUC_PR_C0\", \"F1_C0\", \"Accuracy\", \"Balanced_Accuracy\", \"AUC_ROC\", \"MCC\", \"FPR\", \"FNR\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "honey-redhead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Test_data</th>\n",
       "      <th>Recall_C1</th>\n",
       "      <th>Precision_C1</th>\n",
       "      <th>AUC_PR_C1</th>\n",
       "      <th>F1_C1</th>\n",
       "      <th>Recall_C0</th>\n",
       "      <th>Precision_C0</th>\n",
       "      <th>AUC_PR_C0</th>\n",
       "      <th>F1_C0</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced_Accuracy</th>\n",
       "      <th>AUC_ROC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>whole</td>\n",
       "      <td>3236</td>\n",
       "      <td>0.609667</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.481333</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.908667</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.742667</td>\n",
       "      <td>0.855333</td>\n",
       "      <td>0.405333</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group  Test_data  Recall_C1  Precision_C1  AUC_PR_C1     F1_C1  Recall_C0  \\\n",
       "0  whole       3236   0.609667         0.395   0.481333  0.476667   0.875667   \n",
       "\n",
       "   Precision_C0  AUC_PR_C0     F1_C0  Accuracy  Balanced_Accuracy   AUC_ROC  \\\n",
       "0         0.945   0.976667  0.908667     0.845           0.742667  0.855333   \n",
       "\n",
       "        MCC       FPR    FNR  \n",
       "0  0.405333  0.012433  0.039  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "graduate-bailey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recall_C1</th>\n",
       "      <td>0.609667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision_C1</th>\n",
       "      <td>0.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_C1</th>\n",
       "      <td>0.476667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_PR_C1</th>\n",
       "      <td>0.481333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.405333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_ROC</th>\n",
       "      <td>0.855333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.845000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "Recall_C1     0.609667\n",
       "Precision_C1  0.395000\n",
       "F1_C1         0.476667\n",
       "AUC_PR_C1     0.481333\n",
       "MCC           0.405333\n",
       "AUC_ROC       0.855333\n",
       "Accuracy      0.845000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original -- 'Average', 'std'\n",
    "# decomp_original -- 'prediction'\n",
    "matric_compare = df_full[[\"Recall_C1\",\"Precision_C1\", \"F1_C1\", \"AUC_PR_C1\", \"MCC\", \"AUC_ROC\", \"Accuracy\"]].T\n",
    "matric_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "small-snowboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['result_temp_test_isotonic_0.csv', 'result_temp_test_isotonic_1.csv', 'result_temp_test_isotonic_2.csv']\n",
      "   Group  Test_data  Recall_C1  Precision_C1  AUC_PR_C1  F1_C1  Recall_C0  \\\n",
      "0  Black        290      0.536         0.326      0.393  0.405      0.882   \n",
      "1  Black        290      0.357         0.333      0.379  0.345      0.924   \n",
      "2  Black        290      0.607         0.321      0.413  0.420      0.863   \n",
      "\n",
      "   Precision_C0  AUC_PR_C0  F1_C0  Accuracy  Balanced_Accuracy  AUC_ROC  \\\n",
      "0         0.947      0.969  0.913     0.848              0.709    0.795   \n",
      "1         0.931      0.973  0.927     0.869              0.640    0.803   \n",
      "2         0.954      0.979  0.906     0.838              0.735    0.839   \n",
      "\n",
      "     MCC     FPR    FNR  \n",
      "0  0.337  0.0118  0.046  \n",
      "1  0.272  0.0076  0.064  \n",
      "2  0.359  0.0137  0.039  \n"
     ]
    }
   ],
   "source": [
    "# age or race with all results\n",
    "\n",
    "models = ['original']\n",
    "\n",
    "group = 4 #  age90 = 14; black=4\n",
    "\n",
    "full_list = []\n",
    "full_list_std = []\n",
    "for mod in models:\n",
    "    model_path = r\"csv_files/\"+ mod + \"/test/\"\n",
    "    \n",
    "    \n",
    "    files = [f for f in listdir(model_path) if fnmatch.fnmatch(f, '*result*.csv')]   \n",
    "    \n",
    "    for file in files:\n",
    "        df = pd.read_csv(model_path  + file)\n",
    "        full_list.append(list(df.loc[group]))\n",
    "\n",
    "    print(files)\n",
    "    \n",
    "\n",
    "df_full = pd.DataFrame(full_list, columns= [\"Group\", \"Test_data\", \"Recall_C1\", \"Precision_C1\", \"AUC_PR_C1\", \"F1_C1\", \"Recall_C0\", \"Precision_C0\", \"AUC_PR_C0\", \"F1_C0\", \"Accuracy\", \"Balanced_Accuracy\", \"AUC_ROC\", \"MCC\", \"FPR\", \"FNR\"])\n",
    "print(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "becoming-lexington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recall_C1</th>\n",
       "      <th>Precision_C1</th>\n",
       "      <th>F1_C1</th>\n",
       "      <th>AUC_PR_C1</th>\n",
       "      <th>MCC</th>\n",
       "      <th>AUC_ROC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.536</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.607</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recall_C1  Precision_C1  F1_C1  AUC_PR_C1    MCC  AUC_ROC  Accuracy\n",
       "0      0.536         0.326  0.405      0.393  0.337    0.795     0.848\n",
       "1      0.357         0.333  0.345      0.379  0.272    0.803     0.869\n",
       "2      0.607         0.321  0.420      0.413  0.359    0.839     0.838"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matric_compare = df_full[[\"Recall_C1\",\"Precision_C1\", \"F1_C1\", \"AUC_PR_C1\", \"MCC\", \"AUC_ROC\", \"Accuracy\"]]\n",
    "matric_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-dimension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "breeding-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "matric_compare.to_csv('fig_4_black_matric_compare_ihm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-initial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-logan",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
